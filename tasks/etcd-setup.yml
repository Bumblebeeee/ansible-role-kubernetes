---
- name: Check if etcd cluster already exists
  ansible.builtin.stat:
    path: /etc/kubernetes/pki/etcd/ca.key
  when: inventory_hostname == groups['etcd'][0]
  register: etcd_ca_key_stat

- name: Generate CA for etcd cluster
  command: >
    kubeadm init phase certs etcd-ca
  register: kubeadmin_init
  when:
    - inventory_hostname == groups['etcd'][0]
    - not etcd_ca_key_stat.stat.exists

- name: Generate etcd ha cluster init_configuration
  set_fact:
    etcd_endpoints: >-
      {%- set endpoints = [] -%}
      {%- for host in groups['etcd'] -%}
        {%- set hostname = hostvars[host]['ansible_hostname'] -%}
        {%- set _ = endpoints.append(hostname + '=https://' + host + ':2380') -%}
      {%- endfor -%}
      {{ endpoints | join(',') }}

- name: Create the directory for the etcd_kubeadm_config_file
  file:
    path: "{{ etcd.etcd_config_file_path | dirname }}"
    state: directory

- name: Deploy the config-file for kubeadm
  template:
    src: "etcd-kubeadm-config.j2"
    dest: "{{ etcd.etcd_config_file_path }}"

- name: Create the directory for the drop-in kubelet config
  file:
    path: "{{ etcd.kubelet_config_drop_in_location }}"
    state: directory

- name: Deploy systemd drop-in kubelet service 
  template:
    src: "20-etcd-service-manager.j2"
    # dest: "/usr/lib/systemd/system/kubelet.service.d/20-etcd-service-manager.conf"
    dest: "{{ etcd.kubelet_config_drop_in_location }}/20-etcd-service-manager.conf"

- name: Deploy systemd drop-in kubelet service config 
  template:
    src: "etcd-kubelet-config.j2"
    dest: "{{ etcd.kubelet_config_drop_in_location }}/etcd-kubelet.yaml"
  notify:
    - systemd daemon_reload
    - restart kubelet

- name: Ensure the ca directory exists
  file:
    path: "/etc/kubernetes/pki/etcd"
    state: directory
    mode: '0755'

- name: Copy etcd-ca from the first etcd nodes
  delegate_to: "{{ groups['etcd'][0] }}"
  synchronize:
    src: "/etc/kubernetes/pki/etcd/{{ item }}"
    dest: "/etc/kubernetes/pki/etcd/"
    rsync_opts:
      - "--rsync-path='sudo rsync'"
      - "--rsh=\"/usr/bin/ssh -i /home/{{ hostvars[groups['etcd'][0]].ansible_user }}/.ssh/id_rsa -S none -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null\""
  with_items: 
    - ca.crt
    - ca.key

# - name: Download etcd-ca, etcd-key from s3
#   aws_s3:
#     bucket: "{{ etcd_ca_bucket }}"
#     object: "{{ item.s3_path }}"
#     dest: "{{ item.local_path }}"
#     mode: get
#   with_items:
#     - { s3_path: "{{ etcd_ca_cert }}", local_path: '/etc/kubernetes/pki/etcd/ca.crt' }
#     - { s3_path: "{{ etcd_ca_key }}", local_path: '/etc/kubernetes/pki/etcd/ca.key' }
#   environment:
#     AWS_PROFILE: "{{ aws_profile }}"

# - name: Set permissions on downloaded files
#   file:
#     path: "{{ item.local_path }}"
#     owner: "{{ item.owner }}"
#     group: "{{ item.owner }}"
#     mode: "{{ item.mode }}"
#   with_items:
#     - { local_path: '/etc/kubernetes/pki/etcd/ca.crt', owner: 'root', mode: '0644' }
#     - { local_path: '/etc/kubernetes/pki/etcd/ca.key', owner: 'root', mode: '0600' }


# kubeadm init phase certs etcd-server --config=/tmp/${HOST2}/kubeadmcfg.yaml
# kubeadm init phase certs etcd-peer --config=/tmp/${HOST2}/kubeadmcfg.yaml
# kubeadm init phase certs etcd-healthcheck-client --config=/tmp/${HOST2}/kubeadmcfg.yaml
# kubeadm init phase certs apiserver-etcd-client --config=/tmp/${HOST2}/kubeadmcfg.yaml
- name: Run kubeadm init phase certs
  command: kubeadm init phase certs "{{ item }}"
  loop:
    - etcd-server
    - etcd-peer
    - etcd-healthcheck-client
    - apiserver-etcd-client
  args:
    creates: "/etc/kubernetes/pki/{{ item | regex_replace('^etcd-', 'etcd/') }}.key"

# kubeadm init phase etcd local --config=/tmp/${HOST0}/kubeadmcfg.yaml
- name: Run kubeadm init phase etcd local (if etcd is not running)
  command: >
    kubeadm init phase etcd local 
    --config={{ etcd.etcd_config_file_path }}
  args:
    creates: "/etc/kubernetes/manifests/etcd.yaml"
  notify: 
    - restart kubelet

- name: Flush handlers to restart kubelet immediately
  meta: flush_handlers

- name: Verify if etcd is up and running
  environment:
    ETCDCTL_API: "3"
  command: >
    etcdctl
    --cert /etc/kubernetes/pki/etcd/peer.crt
    --key /etc/kubernetes/pki/etcd/peer.key
    --cacert /etc/kubernetes/pki/etcd/ca.crt
    --endpoints https://{{ inventory_hostname }}:2379 endpoint health
  register: etcd_health_status
  failed_when: "'successfully' not in etcd_health_status.stderr"
  changed_when: false
  retries: 12
  delay: 5
